{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                               Feed Sentiment\n",
      "0   1   اربد فيها جامعات اكثر من عمان ... وفيها قد عم...  Positive\n",
      "1   2   الحلو انكم بتحكوا على اساس انو الاردن ما فيه ...  Negative\n",
      "2   3                            كله رائع بجد ربنا يكرمك  Positive\n",
      "3   4                                 لسانك قذر يا قمامه  Negative\n",
      "4   5  ​انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش...  Negative\n",
      "        ID                                               Feed Sentiment\n",
      "1776  1777                            يع حاسه حالي بدي استفرغ  Negative\n",
      "1473  1474  نعم احسنت واجبه على كل مسلم وحق لكل مسلم فتح ا...  Positive\n",
      "326    327                   اللهم اجعلني من يتشرف به الاسلام  Positive\n",
      "1283  1284                     لو نريد الخشوع حقا نطلق الدنيا  Positive\n",
      "1098  1099                                          قرف يقرفك  Negative\n"
     ]
    }
   ],
   "source": [
    "# Loading Data with xlsx format but Pandas blocks this format for security reasons so we used 'openpyxl' engine to load the data\n",
    "data = pd.read_excel('AJGT.xlsx', engine='openpyxl')\n",
    "print(data.head())\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To download stoping words from NLTK\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                               Feed Sentiment\n",
      "0   1  اربد جامعات اكثر عمان وفيها عمان ونص لعيبه الم...  Positive\n",
      "1   2   الحلو انكم بتحكوا علي اساس انو الاردن فساد سرقات  Negative\n",
      "2   3                            كله راءع بجد ربنا يكرمك  Positive\n",
      "3   4                                    لسانك قذر قمامه  Negative\n",
      "4   5  ​انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش...  Negative\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The first step is to subject the data to preprocessing.\n",
    "This involves removing both arabic and english punctuation\n",
    "Normalizing different letter variants with one common letter\n",
    "'''\n",
    "# first we define a list of arabic and english punctiations that we want to get rid of in our text\n",
    "\n",
    "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation\n",
    "\n",
    "# Arabic stop words with nltk\n",
    "stop_words = stopwords.words()\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Shadda\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    '''\n",
    "    text is an arabic string input\n",
    "    \n",
    "    the preprocessed text is returned\n",
    "    '''\n",
    "    \n",
    "    #remove punctuations\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    # remove Tashkeel\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    \n",
    "    #remove longation\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "    return text\n",
    "  \n",
    "data['Feed'] = data['Feed'].apply(preprocess)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.80      0.82       176\n",
      "    Positive       0.82      0.86      0.84       184\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.83      0.83      0.83       360\n",
      "weighted avg       0.83      0.83      0.83       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# splitting the data into target and feature\n",
    "feature = data.Feed\n",
    "target = data.Sentiment\n",
    "# splitting into train and tests\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size =.2, random_state=100)\n",
    "\n",
    "# make pipeline\n",
    "#TF-IDF is term frequency-inverse document frequency, indicates what the importance of the word is in order to understand the document or dataset\n",
    "pipe = make_pipeline(TfidfVectorizer(), \n",
    "                    LogisticRegression())\n",
    "# make param grid\n",
    "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.76      0.82       176\n",
      "    Positive       0.80      0.91      0.85       184\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.84      0.83      0.83       360\n",
      "weighted avg       0.84      0.83      0.83       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(),\n",
    "                    MultinomialNB())\n",
    "pipe.fit(X_train,Y_train)\n",
    "prediction = pipe.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.82\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(),\n",
    "                    RandomForestClassifier())\n",
    "\n",
    "param_grid = {'randomforestclassifier__n_estimators':[10, 100, 1000],\n",
    "             'randomforestclassifier__max_features':['sqrt', 'log2']}\n",
    "\n",
    "rf_model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "rf_model.fit(X_train,Y_train)\n",
    "\n",
    "prediction = rf_model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.87      0.85       176\n",
      "    Positive       0.87      0.83      0.85       184\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.85      0.85      0.85       360\n",
      "weighted avg       0.85      0.85      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(),\n",
    "                     SVC())\n",
    "param_grid = {'svc__kernel': ['rbf', 'linear', 'poly'],\n",
    "             'svc__gamma': [0.1, 1, 10, 100],\n",
    "             'svc__C': [0.1, 1, 10, 100]}\n",
    "\n",
    "svc_model = GridSearchCV(pipe, param_grid, cv=3)\n",
    "svc_model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = svc_model.predict(X_test)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3129a5684c02928d6dda4f04be9fbdf34f51e4f5be82c48eb8dd386b423b224c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
